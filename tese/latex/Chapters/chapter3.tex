%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% chapter3.tex
%% NOVA thesis document file
%%
%% Chapter with a short latex tutorial and examples
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\typeout{NT FILE chapter3.tex}%

\makeatletter
\newcommand{\ntifpkgloaded}{%
  \@ifpackageloaded%
}
\makeatother


\chapter{State of the Art}
\label{cha:state_of_the_art}

\textbf{Definition: Structural equivalence.} We say that two programs are structurally equivalent if they present the same sequence statements/commands.
For example, a program \emph{$P_1$} that consists in two assignments and a while loop is not equivalent to another program program \emph{$P_2$} if the latter's structure is a single for loop.
On the other hand, if \emph{$P_1$} and \emph{$P_2$} both contain, let us say, three assignments followed by a for loop (with a single assignment inside) that executes the same number of iterations, they are structurally equivalent, despite the values being assigned to the variables.

Note that this definition is useful when reading about self-composition and cross-products below in this capter.
However, we aim to allow verification of programs that would not be considered by this definition of structural equivalence and therefore be more flexible, but we still need some degree of similarity.
That is why we do not target programs that include exceptions.


\section{Self-composition} 
\label{sec:self_composition}

\subsection{Introduction}
\label{subsec:self_composition_intro}

The proposal of self-composition ~\cite{DBLP:conf/csfw/BartheDR04} is to offer an extensible and flexible way of controlling information flow.
This is usually done by information flow type systems, but they suffer from the issues that self-composition attempted to solve.
In the work mentioned above, the authors tried to address the static enforcement of information flow policies but focused on a specific one called non-interference.
Non-interference separates the state of a program into a public and a secret part and, by observing its execution, determines if there was a information leak on the secret part of the state.

Despite the well-defined focus, the efforts of the work specified before apply to several programming languages and different definitions of security, even including declassification, partially.
In the end, the authors were able to establish a general theory of self-composition to prove that programs are non-interfering.
One of the main features of self-composition is its expressiveness and that there is no need to prove the soundness of type systems, since it is based on logic.


\subsection{Exploring non-interference}
\label{subsec:exploring_non_interference}

In order to give an example of self-composition in the next subsection, we present now a simple program that respects the properties of termination-insensitivity and non-interference.

Consider a simple, deterministic and imperative language that allows sequential composition and the evaluation relation \(\langle P, u\rangle \Downarrow v\), where \(P\) is a program and \(u,v\) are memories.
Memory in this context means a map where the keys are the program variables of \(P\) and the values are the values of those program variables.
Furthermore, consider that all variables of \(P\) need to be either public or private, let \(\overrightarrow{x}\) be the set of all public variables in \(P\) and \(\overrightarrow{y}\) the set of all of its private variables.
For all memories \(u_1,u_2,v_1,v_2\), the properties of termination-insensitivity and non-interference for \(P\) can be described as:

\[ [\langle P, u_1\rangle \Downarrow v_1 \, \land \, \langle P, u_2\rangle \Downarrow v_2 \, \land \, u_1 {=}_{L} u_2] \Rightarrow v_1 {=}_{L} v_2 \]

where ${=}_{L}$ is the point-wise extension of equality on values to public parts of memories.

Consider [\(\overrightarrow{x'}, \overrightarrow{y'} / \overrightarrow{x}, \overrightarrow{y}\)] as being a renaming of the program variables \(\overrightarrow{x}\) and \(\overrightarrow{y}\) of \(P\) with fresh variables \(\overrightarrow{x'}\), \(\overrightarrow{y'}\) and let \(P'\) be as \(P\) but with its variables renamed: \(P\)[\(\overrightarrow{x'}, \overrightarrow{y'} / \overrightarrow{x}, \overrightarrow{y}\)].
Also, to refer to the the disjoint union of two memories we will use the $\uplus$ symbol.
Therefore, we have \(\langle P, u\rangle \Downarrow v \, \land \, \langle P', u'\rangle \Downarrow v' \) iff \(\langle P; P, u \uplus u' \rangle \Downarrow v \uplus v'\).
We can now rearrange non-interference, for memories \(u,u',v,v'\), as the following:

\[ (\langle P; P, u \uplus u' \rangle \Downarrow v \uplus v' \, \land \, u = {}_{\overrightarrow{x}} u' \circ [\overrightarrow{x} / \overrightarrow{x'}]) \Rightarrow v = {}_{\overrightarrow{x}} v' \circ [\overrightarrow{x} / \overrightarrow{x'}] \]

where $\circ$ is the symbol for function composition and \(= {}_{\overrightarrow{x}}\) is the point-wise extension of equality on values to the restriction of memories to $\overrightarrow{x}$.
With this formulation, we are able to reduce the non-interference property of \(P\) to a property of all the executions of \(P; P'\).
Therefore, an alternative characterization of non-interference can be presented by using programming logics, since they are sound and relatively complete with relation to the operational semantic.
We can describe non-interference using Hoare triples:

\[ \{\overrightarrow{x} = \overrightarrow{x'}\} \, P; P' \, \{\overrightarrow{x} = \overrightarrow{x'}\} \]


\subsection{Code Example}
\label{subsec:self_composition_example}

Consider the following program:

\[ x := y; \, x := 0 \]

and \(x \mapsto x'\) and \(y \mapsto y'\) as the renaming functions. 
The program is non-interferent iff

\[ \{x = x'\} \, x := y; x := 0 \, x' := y'; x' := 0 \, \{x = x'\} \]

We are able to characterize information flow policies, which include some types of declassification, through the replacement of the =- relation by other (partial) equivalence relation.
More generally, this form of characterization allows us to use existing verification tools to prove (or disprove) information flow policies for a given program.


\FloatBarrier
\section{Cross-products} 
\label{sec:cross_products}

Cross-products~\cite{DBLP:conf/fm/ZaksP08} aim to prove program equivalence, with a strong focus on verifying compiler optimizations.
Instead of proving that both programs are equivalent, the analysis is done by combining the two input programs into one: the cross-product.
With them, instead of recurring to program analysis and proof rules developed specifically for translation validation, it became possible to use existing methods and tools to prove properties of a single program. 
Despite handling the most common intraprocedural compiler optimizations, cross-products can not be applied to two input programs with dissimilar structures, which is a major constraint of this work.

One important aspect of CoVaC, a framework developed by the authors of the aforementioned article, is that it was made to validate program equivalence in general while balancing precision and efficiency.
The approach was to divide the analysis in two phases, a faster one first and a more precise after that.
The first phase utilizes a fast, yet imprecise value numbering algorithm whose results are used to determine if it is necessary to apply the second phase. 
This final part is based on assertion checking, a static program verification method which, under the hood, computes the weakest-precondition~\cite{DBLP:books/ph/Dijkstra76} using CVC3~\cite{cvc3}. 

The results presented on the cited work reveal that CoVaC was able to verify a very considerable set of optimizations of LLVM~\cite{llvm}, a complex modern compiler.
Yet, the tool does not support verification of interprocedural optimizations or information flow policies, for example, but these are limitations that the authors showed interest in addressing.


\FloatBarrier
\section{Product Programs} 
\label{sec:product_programs}

\subsection{Motivation} 
\label{subsec:product_programs_motivation}

Relational Hoare Logic serves as a good starting point to compare the behavior of two different executions of the same program or even two different programs.
However, there are few available tools and practical reasoning logics for relational verification.
One of the main limitations of the existing ones~\cite{DBLP:conf/popl/Benton04, DBLP:journals/tcs/Yang07} is the constraint of \emph{structural equivalence}.
Inversely, traditional program verification has diverse and extensive tool support.
Therefore, as a way of getting around that limitation, we can take advatange of the existing tool support if we are able to soundly reduce relational verification tasks into standard verification ones.
This means we would translate Hoare quadruples (\{$\Phi$\} \emph{$P_1$} \emph{\textasciitilde} \emph{$P_2$} \{$\Psi$\}) into Hoare triples (\{$\phi$\} \emph{P} \{$\psi$\}), making sure that: if the original quadruple is valid, then the generated triple is also valid; if the if the original quadruple is not valid, the generated triple would also be invalid.
Considering $\vDash$ the symbol for validity, the objective is finding \emph{$\phi$, P, $\psi$} that:
\[ \vDash \{\Phi\} \, \textbf{$P_1$} \sim \textbf{$P_2$} \, \{\Psi\} \ \ \ \rightarrow \ \ \ \ \ \vDash \{\phi\} \, \textbf{P} \, \{\psi\} \]

Let us consider two imperative and \emph{separable} programs \emph{$P_1$} and \emph{$P_2$}.
This enables the capacity of the assertions to be seen as first-order formulas about the variables of \emph{$P_1$} and \emph{$P_2$}.
Self-composition~\cite{DBLP:conf/csfw/BartheDR04} represents a way of establishing the wanted equalities mentioned above: \emph{P $\equiv$ $P_1$;$P_2$}, \emph{$\phi$ $\equiv$ $\Phi$} and \emph{$\psi$ $\equiv$ $\Psi$}.
Despite being characterized by soundness and relative completeness~\cite{DBLP:journals/jlp/BartheCK16}, this construction is impractical for the authors of this~\cite{DBLP:conf/sas/TerauchiA05} work.
One of the two main reasons is that the existing automatic safety analysis tools available are not powerful enough to verify most of realistic problems and, when they can, there is a lack of performance.
The other reason is that the safety analysis developed for naturally 1-safety problems is not expected to advance significantly in the foreseeable future.

There is another relevant method previously discussed in this \hyperref[sec:cross_products]{this} section, the cross-products.
These suffer from the constraint of structural equivalence, making impossible to reason about properties or program optimizations that are based on different control flows.

Product Programs~\cite{DBLP:conf/fm/BartheCK11} appear to be the best path to follow, since they represent a general notion that combines the flexibility of self-composition in executing asynchronous steps and the efficiency of cross-products when it comes to treat synchronous steps. 
Product programs are a way to reduce relational verification into standard verification through the construction of a product program \emph{P} that simulates the execution statements of any two programs \emph{$P_1$} and \emph{$P_2$}.


\FloatBarrier
\subsection{From relational verification to standard verification} 
\label{subsec:product_programs_relverif_to_stdverif}

\subsubsection{A first intuition} 
\label{subsubsec:product_programs_intuition}

As a way to provide a first intuition of construction of a product from structurally dissimilar programs before we dive into the definitions and rules later in this subsection, consider the simple \hyperref[fig:pp_first_intuition]{example} below (assume 0 $\leq$ N).

\begin{figure}[h]
  \centering

  \begin{subfigure}[t]{0.28\textwidth}
    \centering
    \makebox[\linewidth][l]{\textbf{Source program}}\par\smallskip
    \noindent
    \begin{lstlisting}[escapeinside={(*}{*)}, style=while_lang, linewidth=\linewidth, xleftmargin=0pt, framexleftmargin=0pt]
@i := 1@; 
while (@i (*$\textcolor{red}{\leq}$*) N@) do
  @x += i@;
  @i++@
    \end{lstlisting}
  \end{subfigure}\hfill%
  \begin{subfigure}[t]{0.28\textwidth}
    \centering
    \makebox[\linewidth][l]{\textbf{Transformed program}}\par\smallskip
    \noindent
    \begin{lstlisting}[escapeinside={(*}{*)}, style=while_lang, linewidth=\linewidth, xleftmargin=0pt, framexleftmargin=0pt]
çj := 1ç; 
while (çj (*$\textcolor{blue}{\leq}$*) Nç) do
  çy += jç;
  çj++ç
    \end{lstlisting}
  \end{subfigure}\hfill%
  \begin{subfigure}[t]{0.4\textwidth}
    \centering
    \makebox[\linewidth][l]{\textbf{Product program}}\par\smallskip
    \noindent
    \begin{lstlisting}[escapeinside={(*}{*)}, style=while_lang, linewidth=\linewidth, xleftmargin=0pt, framexleftmargin=0pt]
@i := 1@; @x += i@; @i++@; çj := 1ç;
while (@i (*$\textcolor{red}{\leq}$*) N@) do
  @x += i@; @i++@;
  çy += jç; çj++ç
    \end{lstlisting}
  \end{subfigure}

  \caption{First intuition source, transformed and product programs.}
  \label{fig:pp_first_intuition}
\end{figure}

The first step to build the product program is to unroll the first loop iteration of the source code before synchronizing the loop statements.
Rather than relying plainly on self-composition, this idea maximizes synchronization and differs from a functional interpretation of the product components.
Furthermore, this approach also reduces considerably the complexity of the invariants required to prove the product program.
In the case of a sequential composition of the source and transformed programs, we would need to provide invariants of the form \emph{x = X + $\frac{i(i-1)}{2}$} and \emph{y = Y + $\frac{j(j-1)}{2}$}, respectively, assuming the pre-conditions \emph{x = X} and \emph{y = Y}.
On the other hand, if we construct the product program, the loop invariant \emph{i = j $\land$ x = y} is enough to verify that the two first programs above satisfy the pre and post-relation \emph{x = y}.


\FloatBarrier
\subsubsection{Establishing the ground rules} 
\label{subsubsec:product_programs_ground_rules}

The commands in our programming model will stick to the grammar defined previously \hyperref[sub:relational_hoare_logic_formal_proof_rules]{here}, but we redefine some of its components in a more specific way.

\emph{x} ranges over a set of integer variables V$_i$, \emph{a} ranges over a set of array variables V$_a$, let V denote V$_i$ $\cup$ V$_a$, and assuming V$_i$ $\cap$ V$_a$ = $\emptyset$.
Let \emph{e} $\in$ AExp and \emph{b} $\in$ BExp range over integer and boolean expressions.
Their semantics are given by ${(\llbracket e \rrbracket)}_{e \in AExp}$ : S $\rightarrow$ $\mathbb{Z}$ and ${(\llbracket b \rrbracket)}_{b \in BExp}$ : S $\rightarrow$ $\mathbb{B}$, respectively.
Execution states' representation is \emph{S = (V$_i$ $\rightharpoonup$ $\mathbb{Z}$) X (V$_a$ $\rightharpoonup$ ($\mathbb{Z}$ $\rightharpoonup$ $\mathbb{Z}$)).}
The semantics of the commands are standard, deterministic and are based on the relation $\langle$c, $\sigma$$\rangle$ $\rightsquigarrow$ $\langle$c', $\sigma$'$\rangle$.

Notice that $\langle$\textbf{skip}, $\sigma$$\rangle$ marks the end of the programs, \textbf{assert}(b) blocks the execution of the program if \emph{b} is false, and we let $\langle$c, $\sigma$$\rangle$ $\Downarrow$ $\sigma$' mean $\langle$c, $\sigma$$\rangle$ $\rightsquigarrow$* $\langle$\textbf{skip}, $\sigma$'$\rangle$.
An assertion $\phi$ is a first-order formula with variables in V.
We let $\llbracket\phi\rrbracket$ denote the set of states satisfying $\phi$.
Finally, we let var(\emph{c}) $\subseteq$ V and var($\phi$) $\subseteq$ V denote the set of (free) variables of a command c and assertion $\phi$, respectively.

As we discussed before in this document, two commands are \emph{separable} if they operate on disjoint sets of variables.
Similarly, we consider that two states are \emph{separable} if their domains are disjoint.
Consider $\mu$$_1$ $\uplus$ $\mu$$_2$ represent the union of finite maps:
\[
(\mu_1 \uplus \mu_2) \ x =
\begin{cases}
    \mu_1 x & \text{if } x \in \operatorname{dom}(\mu_1) \\
    \mu_2 x & \text{if } x \in \operatorname{dom}(\mu_2)
\end{cases}
\]

and overload this notation for the union of separable states ($\mu$,$\nu$) $\uplus$ ($\mu$',$\nu$'), whose definition is ($\mu$ $\uplus$ $\mu$', $\nu$ $\uplus$ $\nu$').
Taking into account that we assume that the states are separable, another way of looking at assertions is by viewing them as relations on states: ($\sigma$$_1$, $\sigma$$_2$) $\in$ $\llbracket$$\phi$$\rrbracket$ iff $\sigma$$_1$ $\uplus$ $\sigma$$_2$ $\in$ $\llbracket$$\phi$$\rrbracket$.
Therefore, the definition below illustrates the formal statement of valid relational specifications.
\bigskip

\textbf{Definition 1 -}  \emph{Two commands $c_1$ and $c_2$ satisfy the pre-condition $\phi$ and the post-condition $\psi$ described by a valid Hoare quadruple if,
                                for all states $\sigma$$_1$, $\sigma$$_2$, $\sigma$$_1$', $\sigma$$_2$' such that $\sigma_1$ $\uplus$ $\sigma_2$ $\in$ $\llbracket$$\phi$$\rrbracket$
                                and $\langle$$c_1$, $\sigma$$_1$$\rangle$ $\Downarrow$ $\sigma$$_1$' and $\langle$$c_2$, $\sigma$$_2$$\rangle$ $\Downarrow$ $\sigma$$_2$', we have $\sigma_1$' $\uplus$ $\sigma_2$' $\in$ $\llbracket$$\psi$$\rrbracket$.}

\bigskip
Since our objective is to reduce the validity of Hoare quadruples to validity of Hoare triples, we must say that we establish our notion of valid Hoare triple as stronger than usual.
It requires that the command allows the program to finish its execution, i.e., the command is \emph{non-stuck}.
\bigskip

\textbf{Definition 2 -}  \emph{A Hoare triple {$\phi$} c {$\psi$} is valid ($\vDash$ \{$\phi$\} c \{$\psi$\}) if c is $\phi$-nonstuck and for all $\sigma$, $\sigma$' $\in$ S, $\sigma$ $\in$ $\llbracket$$\phi$$\rrbracket$ and $\langle$c, $\sigma$$\rangle$ $\Downarrow$ $\sigma$' imply $\sigma$' $\in$ $\llbracket$$\psi$$\rrbracket$.}

\bigskip
This notion of validity requires, however, that we extend Hoare logic for it to be able to treat \textbf{assert} statements.
The necessary rule is:
\begin{figure}[h]
  \begin{center}
    \begin{minipage}{\linewidth}
      \centering
      \begin{mathpar}
        \inferrule*[] { } {\vdash \ \{ \textit{b} \land \Phi \} \ \textbf{assert}\text{(b)} \ \{ \Phi \}}
      \end{mathpar}
    \end{minipage}
  \end{center}
\end{figure}


\FloatBarrier
\subsubsection{Construction of Product Programs} 
\label{subsubsec:product_programs_construction}

Firstly in this section, we define the rules that will be used to deal with structurally equivalent programs. 
After that, we increment that set with structural transformations to allow the treatment of programs with different structures.

\begin{figure}[h]
  \centering
  \begin{mathpar}

  \inferrule*[]
    { }
    {c_1 \times c_2 \; \rightarrow \; c_1 ; c_2}

  \inferrule*[]
    {c_1 \times c_2 \; \rightarrow \; c \\ 
     c'_1 \times c'_2 \; \rightarrow \; c'}
    {(c_1 ; c'_1) \times (c_2 ; c'_2) \; \rightarrow \; c ; c'}

  \inferrule*[]
    {c_1 \times c_2 \; \rightarrow \; c}
    {(\textbf{while} \; b_1 \; \textbf{do} \; c_1) \times (\textbf{while} \; b_2 \; \textbf{do} \; c_2) \; \rightarrow \;
    \textbf{assert}(b_1 \Leftrightarrow b_2); \; \textbf{while} \; b_1 \; \textbf{do} \; (c ; \textbf{assert}(b_1 \Leftrightarrow b_2))}

  \inferrule*[]
    {c_1 \times c_2 \; \rightarrow \; c \\ 
    c'_1 \times c'_2 \; \rightarrow \; c'}
    {(\textbf{if} \; b_1 \; \textbf{then} \; c_1 \; \textbf{else} \; c'_1) \times (\textbf{if} \; b_2 \; \textbf{then} \; c_2 \; \textbf{else} \; c'_2) \; \rightarrow \;
    \textbf{assert}(b_1 \Leftrightarrow b_2); \; \textbf{if} \; b_1 \; \textbf{then} \; c \; \textbf{else} \; c'}

  \inferrule*[]
    {c_1 \times c \; \rightarrow \; c'_1 \\ 
    c_2 \times c \; \rightarrow \; c'_2}
    {(\textbf{if} \; b \; \textbf{then} \; c_1 \; \textbf{else} \; c_2) \times c \; \rightarrow \;
    \textbf{if} \; b \; \textbf{then} \; c'_1 \; \textbf{else} \; c'_2}  
    
  \end{mathpar}
  \caption{Product construction rules.}
  \label{fig:product_construction_equal_struct}
\end{figure}

The \hyperref[fig:product_construction_equal_struct]{figure} describes a set of rules to derive a product construction judgment of the type \emph{c$_1$ $\times$ c$_2$ $\rightarrow$ c.}
To make sure that \emph{c} simulates with precision the behavior of \emph{c$_1$ and c$_2$}, the construction of products introduces \textbf{assert} statements.
During the phase of the verification of the program, these validation constraints are viewed as local assertions and discharged.
Let us consider the rule that synchronizes two loops, for example: \textbf{assert}(b$_1$ $\Leftrightarrow$ b$_2$) is necessary to guarantee that the number of iterations of each loop is the same.
This achieves what we aimed for, that is, the product program can be verified with standard logic.
\bigskip

\textbf{Proposition 1 -}  \emph{For all statements $c_1$ and $c_2$, pre-condition $\phi$ and post-condition $\psi$, if $c_1$ $\times$ $c_2$ $\rightarrow$ c and $\vDash$ {$\phi$} c {$\psi$} then $\vDash$ {$\phi$} $c_1$ \textasciitilde $c_2$ {$\psi$}.}

\bigskip
In other words, if \emph{c} is the resulting product program of \emph{c1} and \emph{c2}, then we can reason about the validity of the relational judgment between \emph{c1} and \emph{c2} through the validity of the standard judgment of \emph{c}.

As we mentioned before, the rules present in the previous \hyperref[fig:product_construction_equal_struct]{figure} are limited to structurally equivalent programs.
For example, if we consider two programs each with a loop and their guards are not equivalent, the product would have to be sequentially composed.
The structural translations proposed extend the construction of the already defined products in the form of a refinement relation, with a judgment of the form \emph{c} $\succcurlyeq$ \emph{c'}. 
This means that every execution of \emph{c} is an execution of \emph{c'} except when the latter's execution does not terminate:
\bigskip

\textbf{Definition 3 -}  \emph{A command c' is a refinement of c, if, for all states $\sigma$, $\sigma$':}    
\begin{itemize}
  \item{\emph{1. if $\langle$c', $\sigma$$\rangle$ $\Downarrow$ $\sigma$' then $\langle$c, $\sigma$$\rangle$ $\Downarrow$ $\sigma$'}}
  \vspace{-10pt}
  \item{\emph{2. if $\langle$c, $\sigma$$\rangle$ $\Downarrow$ $\sigma$' then either the execution of c' with initial state $\sigma$ gets stuck, or $\langle$c', $\sigma$$\rangle$ $\Downarrow$ $\sigma$'.}}
\end{itemize}

\bigskip
In the \hyperref[fig:product_construction_reduction]{figure} is described the set of rules that define judgments of the form $\vdash$ \emph{c} $\succcurlyeq$ \emph{c'}.

\begin{figure}[h]
  \centering
  \begin{mathpar}

  \inferrule*[]
    { }
    {\vdash \textbf{if} \; b \; \textbf{then} \; c_1 \; \textbf{else} \; c_2 \; \succcurlyeq \; \textbf{assert}(b); \; c_1}
    
  \inferrule*[]
    { }
    {\vdash \textbf{if} \; b \; \textbf{then} \; c_1 \; \textbf{else} \; c_2 \; \succcurlyeq \; \textbf{assert}(\neg b); \; c_2}

  \inferrule*[]
    { }
    {\vdash \textbf{while} \; b \; \textbf{do} \; c \; \succcurlyeq \; \textbf{assert}(b); \; c; \; \textbf{while} \; b \; \textbf{do} \; c}

  \inferrule*[]
    { }
    {\vdash \textbf{while} \; b \; \textbf{do} \; c \; \succcurlyeq \; \textbf{while} \; b \; \land \; b' \; \textbf{do} \; c}  

  \inferrule*[]
    { }
    {\vdash \textbf{while} \; b \; \textbf{do} \; c \; \succcurlyeq \; \textbf{assert}(b); \; c; \; \textbf{assert}(\neg b)}

  \inferrule*[]
    {\vdash c \; \succcurlyeq \; c'}
    {\vdash \textbf{while} \; b \; \textbf{do} \; c \; \succcurlyeq \; \vdash \textbf{while} \; b \; \textbf{do} \; c'}

  \inferrule*[]
    {\vdash c_1 \; \succcurlyeq \; c'_1 \\ \vdash c_2 \; \succcurlyeq \; c'_2}
    {\vdash \textbf{if} \; b \; \textbf{then} \; c_1 \; \textbf{else} \; c_2 \; \succcurlyeq \; \textbf{if} \; b \; \textbf{then} \; c'_1 \; \textbf{else} \; c'_2}

  \inferrule*[]
    {\vdash c \; \succcurlyeq \; c' \\ \vdash c' \; \succcurlyeq \; c''}
    {\vdash c \; \succcurlyeq \; c''}

  \inferrule*[]
    { }
    {\vdash c \; \succcurlyeq \; c}

  \inferrule*[]
    {\vdash c_1 \; \succcurlyeq \; c'_1 \\ \vdash c_2 \; \succcurlyeq \; c'_2}
    {\vdash c_1 ; c_2 \; \succcurlyeq \; c'_1 ; c'_2}
    
  \end{mathpar}
  \caption{Syntactic reduction rules.}
  \label{fig:product_construction_reduction}
\end{figure}

One can see that the \hyperref[fig:product_construction_reduction]{rules} point that the executions of \emph{c} and \emph{c'} match for every initial state that makes the introduced \textbf{assert} statements valid.
It is possible to prove that the judgment \emph{c} $\succcurlyeq$ \emph{c'} maintains a refinement relation by showing that, for every assertion $\phi$, if c' is $\phi$-nonstuck, then for all $\sigma$ $\in$ $\llbracket$$\phi$$\rrbracket$ such that $\langle$c, $\sigma$$\rangle$ $\Downarrow$ $\sigma$' we have $\langle$c', $\sigma$$\rangle$ $\Downarrow$ $\sigma$'.
We add one more rule that makes a preliminary refinement transformation over the product components:

\begin{figure}[H]
  \begin{center}
  \begin{minipage}{\linewidth}
  \centering
    \begin{mathpar}
      \inferrule*[]
        {\vdash c_1 \; \succcurlyeq \; c'_1 \\
        \vdash c_2 \; \succcurlyeq \; c'_2 \\
        c'_1 \times c'_2 \; \rightarrow \; c}
        {c_1 \times c_2 \; \rightarrow \; c}
    \end{mathpar}
  \end{minipage}
  \end{center}
\end{figure}

This does not invalidate \textbf{Proposition 1}. 
Finally, we formally reduce the problem of proving the validity of a relational judgment into the construction of the product program followed by the standard verification of that same product program.
\bigskip

\textbf{Proposition 2 -}  \emph{For all statements $c_1$ and $c_2$, pre-condition $\phi$ and post-condition $\psi$, if $c_1$ $\times$ $c_2$ $\rightarrow$ c and $\vdash$ {$\phi$} c {$\psi$} then $\vDash$ {$\phi$} $c_1$ \textasciitilde $c_2$ {$\psi$}.}

\bigskip


\FloatBarrier
\subsection{Examples} 
\label{subsec:product_programs_examples}

Although product programs can be applied to several relational properties, such as non-interference and continuity, we will focus our examples on the correctness of program optimizations.

\subsubsection{Loop alignment} 
\label{subsubsec:product_programs_loop_alignment}

Loop alignment is an optimization that consists in improving cache effectiveness by increasing the proximity of the memory locations accessed in each iteration of the loop.
\begin{figure}
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \begin{minipage}[t]{\linewidth}
      \textbf{Source program}
      \begin{lstlisting}[escapeinside={(*}{*)}, style=while_lang]
        @i := 1@; 
        while (@i (*$\textcolor{red}{\leq}$*) N@) do
          @b[i] := a[i]@;
          @d[i] := b[i-1]@;
          @i++@
      \end{lstlisting}
    \end{minipage}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \begin{minipage}[t]{\linewidth}
      \textbf{Optimized program}
      \begin{lstlisting}[escapeinside={(*}{*)}, style=while_lang]
        çj := 1ç;
        ç(*$\textcolor{blue}{\overline{d}}$*)[1] := (*$\textcolor{blue}{\overline{b}}$*)[0]ç;
        while (çj (*$\textcolor{blue}{\leq}$*) N-1ç) do
          ç(*$\textcolor{blue}{\overline{b}}$*)[j] := (*$\textcolor{blue}{\overline{a}}$*)[j]ç;
          ç(*$\textcolor{blue}{\overline{d}}$*)[j+1] := (*$\textcolor{blue}{\overline{b}}$*)[j]ç;
          çj++ç;
        ç(*$\textcolor{blue}{\overline{b}}$*)[N] := (*$\textcolor{blue}{\overline{a}}$*)[N]ç
      \end{lstlisting}
    \end{minipage}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.9\textwidth}
    \begin{minipage}[t]{\linewidth}
      \textbf{Product program}
      \begin{lstlisting}[escapeinside={(*}{*)}, style=while_lang]
        {a = (*$\overline{a}$*) (*$\land$*) b[0] = (*$\overline{b}$*)[0]}
          @i := 1@; 
          çj := 1ç;
          assert(@i (*$\textcolor{red}{\leq}$*) N@);
          @b[i] := a[i]@; @d[i] := b[i-1]@; @i++@;
          ç(*$\textcolor{blue}{\overline{d}}$*)[1] := (*$\textcolor{blue}{\overline{b}}$*)[0]ç;
          assert(@i (*$\textcolor{red}{\leq}$*) N@ (*$\Leftrightarrow$*) çj (*$\textcolor{blue}{\leq}$*) N-1ç);
          while (@i (*$\textcolor{red}{\leq}$*) N@) do
            @b[i] := a[i]@; @d[i] := b[i-1]@; @i++@;
            ç(*$\textcolor{blue}{\overline{b}}$*)[j] := (*$\textcolor{blue}{\overline{a}}$*)[j]ç; ç(*$\textcolor{blue}{\overline{d}}$*)[j+1] := (*$\textcolor{blue}{\overline{b}}$*)[j]ç; çj++ç;
            assert(@i (*$\textcolor{red}{\leq}$*) N@ (*$\Leftrightarrow$*) çj (*$\textcolor{blue}{\leq}$*) N-1ç);
          ç(*$\textcolor{blue}{\overline{b}}$*)[N] := (*$\textcolor{blue}{\overline{a}}$*)[N]ç
        {d[1,N] = (*$\overline{d}$*)[1,N]}
      \end{lstlisting}
    \end{minipage}
  \end{subfigure}
  \caption{Loop alignment.}
  \label{fig:loop_alignment}
\end{figure}

Consider \emph{N} $\geq$ 1.
In the source \hyperref[fig:loop_alignment]{program}, note that, in each iteration, the array \emph{b} is accessed twice; firstly in the write to index \emph{i} and secondly in the read of position \emph{i-1}.
What loop alignment does is transform the access of different indexes of \emph{b} into only one index, in this case, \emph{i}.
The corresponding product program starts by ensuring that the number of iterations of the loop is the same for the source and optimized programs, through the assignment statement \emph{$\overline{d}$[1] := $\overline{b}$[0]}.
To be verified, the program product needs a pre-condition, a post-condition and a loop invariant.
The pre-condition is \emph{a = $\overline{a}$ $\land$ b[0] := $\overline{b}$[0]}.
The post-condition is \emph{d[1, N] = $\overline{d}$[1, N]}, meaning that, for the indexes in the interval [1, \emph{N}], the values of the arrays \emph{d} and \emph{$\overline{d}$} are the same.
A suitable loop invariant is \emph{d[1, i) = $\overline{d}$[1, i)  $\land$  b[j] = a[j]  $\land$  $\overline{b}$[i] = b[i]  $\land$  i = j + 1}.
This specification guarantees that, if the input arrays \emph{a} and \emph{b} are equal, the values present in the array \emph{d} are the same when the execution of both product components terminates.

\FloatBarrier
\subsubsection{Induction variable strength reduction} 
\label{subsubsec:product_programs_strength_reduction}

Product programs allow the verification of optimizations that \emph{maintain} the control flow of programs, but simply modify the basic blocks.
Some rather common examples of this are constant propagation and common subexpression elimination.

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \begin{minipage}[t]{\linewidth}
      \textbf{Source program}
      \begin{lstlisting}[escapeinside={(*}{*)}, style=while_lang]
        @i := 0@; 
        while (@i < N@) do
          @j := i * B + C@;
          @x += j@;
          @i++@
      \end{lstlisting}
    \end{minipage}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    \begin{minipage}[t]{\linewidth}
      \textbf{Optimized program}
      \begin{lstlisting}[escapeinside={(*}{*)}, style=while_lang]
        çi(*\textcolor{blue}{\textasciiacute}*) := 0ç;
        çj(*\textcolor{blue}{\textasciiacute}*) := Cç;
        while (çi(*\textcolor{blue}{\textasciiacute}*) < Nç) do
          çx(*\textcolor{blue}{\textasciiacute}*) += j(*\textcolor{blue}{\textasciiacute}*)ç;
          çj(*\textcolor{blue}{\textasciiacute}*) += Bç;
          çi(*\textcolor{blue}{\textasciiacute}*)++ç
      \end{lstlisting}
    \end{minipage}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.9\textwidth}
    \begin{minipage}[t]{\linewidth}
      \textbf{Product program}
      \begin{lstlisting}[escapeinside={(*}{*)}, style=while_lang]
        @i := 0@; çi(*\textcolor{blue}{\textasciiacute}*) := 0ç; çj(*\textcolor{blue}{\textasciiacute}*) := Cç;
        while (@i < N@ (*$\land$*) çi(*\textcolor{blue}{\textasciiacute}*) < Nç) do
          @j := i * B + C@; @x += j@; @i++@
          çx(*\textcolor{blue}{\textasciiacute}*) += j(*\textcolor{blue}{\textasciiacute}*)ç; çj(*\textcolor{blue}{\textasciiacute}*) += Bç; çi(*\textcolor{blue}{\textasciiacute}*)++ç
      \end{lstlisting}
    \end{minipage}
  \end{subfigure}
  \caption{Induction variable strength reduction.}
  \label{fig:induction_var_strength_red}
\end{figure}

The \hyperref[fig:induction_var_strength_red]{figure} demonstrates the effects that applying strength reduction has in a small program.
In the example, \emph{j} is a derived induction variable defined as a linear function on the induction variable \emph{i}.
The optimization in question substitutes the statement \emph{j := i * B + C} by the equivalent and more performant statement \emph{j' += B} (multiplication is more costly than addition to a computer), makes the assignment \emph{x' += j'} come first inside the loop and adds an initial assignment \emph{j' = C} before the start of the loop.
To verify the correctness of the optimization, we need to guarantee that \emph{x = x'} is an invariant of the product program.
And to do that, we need the linear condition \emph{j := i * B + C} to be part of the loop invariant.

\FloatBarrier
\section{WhyRel}
\label{sec:whyrel}

\subsection{Introduction}
\label{subsec:whyrel_intro}

WhyRel~\cite{whyrel} is a tool that aims to verify relational properties of pointer programs based on relational region logic, in an auto-active way.
It also supports state-based encapsulation and dynamic framing. 
This tool appears in a context where there are two existing types of tools exist but are not powerful enough to reduce the gap between them.
One of the types of tools are the ones that do not support well the relational verification of programs that dynamically allocate mutable state; these take much weight off users' shoulders but are only useful to a restrict range of programs.
The other type of tools are the auto-active ones; these enable the verification of a considerably larger set of programs but require more user input.
Note that we will purposefully omit a considerable part of the details about WhyRel, since the verification of pointer programs is out of the scope of this thesis.


\subsection{Implementation details}
\label{subsec:whyrel_specifying}
TODO:
- importante do 2
- importante do 4
- maximal alignments

Some of the most relevant relational properties are conditional program equivalence, non-interference and sensitivity~\cite{barthe2019verifying}.
WhyRel addresses tooling that enables modular verification of relational properties of heap-manipulating programs, including the ones that act on differing data representations and involve dynamically allocated pointer structures.
It reaches modular reasoning about programs that contain pointers through local reasoning, using frame conditions and procedural and data abstraction.
Simpler relational invariants and specs can be achieved through the alignment of intermediate execution steps, a type of compositionality.

WhyRel invests a lot in encapsulation, as a way to hide internal representation details from clients and to verify the modular correctness of a client independently of its internal organization.
Since this challenging on a technical level, WhyRel specifies encapsulation as a \emph{dynamic boundary}, a kind of dynamic frame.
A dynamic boundary captures the set of the module's internal locations.
Therefore, enforcing encapsulation in practice requires making sure that clients do not modify any internal locations of a module.
Relational logic has thorough soundness proofs~\cite{10.1145/3551497} and WhyRel, according to its authors, is an accurate implementation.

This tool should be interpreted as a front-end to Why3, where users provide the code, specifications and annotations and, additionally for relational verification, they should also provide relational specifications and alignments using a syntax for product programs.
After that, WhyRel translates these inputs into WhyML code, enconding them in a way that accurately captures the representation of the heap model and fine-grained framing formalized in relational region logic.
Fianlly, some VCs are added by WhyRel as intermediate assertions and lemmas for the user to confirm, and the verification itself is achieved mainly through the use of the Why3 IDE.

WhyRel was evaluated by its authors through several case studies that demonstrate the effectiveness of relational region logic for alignment, expressing heap relations and relational reasoning that exploits encapsulation.


\subsection{Patterns of program alignment}
\label{subsec:whyrel_patterns}

Choosing alignments to decompose relational verification is an important task since that choice directly impacts how simple the relational assertions and loop invariants can be to prove the program in question.
In this subsection, we present two examples of biprograms that capture alignments that are not maximal.
We will explain what that means below.


\subsubsection{Differing control structures}
\label{subsubsec:diff_control_structs}

\begin{figure}[h]
  \centering

  \begin{subfigure}[t]{0.49\textwidth}
    \centering
    \noindent
    \begin{lstlisting}[escapeinside={(*}{*)}, style=while_lang,
                        emph={meth, while, do, result, done, old, invariant, assert, int},
                        emphstyle=\ttfamily\bfseries\color{myorange}]
meth mult1(n: int, m: int) : int =
  i := 0;

  while (i < n) do
    j := 0;

    while (j < m) do
      result := result + 1;
      j := j + 1;
    done;

    i := i + 1;
  done;
    \end{lstlisting}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{0.49\textwidth}
    \centering
    \noindent
    \begin{lstlisting}[escapeinside={(*}{*)}, style=while_lang,
                        emph={meth, while, do, result, done, old, invariant, assert, int},
                        emphstyle=\ttfamily\bfseries\color{myorange}]
meth mult2(n: int, m: int) : int =
  i := 0;

  while (i < n) do
    result := result + m;
    i := i + 1;
  done;
    \end{lstlisting}
  \end{subfigure}

  \caption{Two different programs that multiply two integer numbers.}
  \label{fig:mult_source_programs}
\end{figure}

In this~\cite{DBLP:conf/pldi/ChurchillP0A19} work, the authors developed a way to establish program equivalence through state-dependent alignments of program traces.
They identified a challenge when trying to confirm the equivalence of two programs that multiply two integer numbers using different control flow, as shown in \hyperref[fig:mult_source_programs]{the} figure.
The challenge arises in the context of automated approaches to relational verification specifically, because of the necessity of aligning an unbounded number \emph{m} of loop iterations on the left (\emph{mult1}) with a single iteration on the right (\emph{mult2}).

\begin{figure}[h]
  \centering
  \noindent
  \begin{lstlisting}[escapeinside={(*}{*)}, style=while_lang, mathescape,
                      emph={meth, while, do, result, done, old, invariant, assert, int},
                      emphstyle=\ttfamily\bfseries\color{myorange}]
meth mult_bip (n: int, m: int | n: int, m: int) : (int | int) =
  $\lfloor$ i := 0 $\rfloor$;

  while (i < n) | (i < n) do
    invariant { i $\doteq$ i $\land$ result $\doteq$ result }

    (
      j := 0;
      while (j < m) do
        result := result + 1;
        j := j + 1;
      done
      |
      result := result + m;
    )

    assert { $\lhd$ result = old(result) + m $\lhd$ };
    $\lfloor$ i := i + 1 $\rfloor$;
  done;
  \end{lstlisting}
  \caption{An example of a biprogram for the example in \hyperref[fig:mult_source_programs]{this} figure.}
  \label{fig:mult_biprogram}
\end{figure}

In order to prove equivalence, we verify the biprogram presented in \hyperref[fig:mult_biprogram]{this} figure.
To achieve that, the pre-relation (or pre-condition) should be \(n \doteq n \land m \doteq m \) and the post-relation (or post-condition) \(result \doteq result\).
The $\doteq$ symbol means that the left side of the expression (only reasoning about the left program) is equal to the right side of the expression (this side also only reasons about the right program).
Therefore, the specification above means that if the input variables have the same values, then the output will also be the same.

We call unary programs the source programs, in this case, \emph{mult1} and \emph{mult2} present in \hyperref[fig:mult_source_programs]{this} figure.
We say that an alignment is maximal if every statement/command is the same for the two unary programs.
This example's alignment is therefore not maximal, since we have two while loops on the left side and only one on the right side.
Nevertheless, we can still explore their similarities through the alignment of the outer loops in lockstep, and the left inner loop with the \emph{result := result+m;} instruction on the right.

Observe that the notation $\lhd F \lhd$ (respectively $\rhd F \rhd$) means that the unary formula \emph{F} is true for the state of the left (respectively right) program.
To prove that \emph{mult1} and \emph{mult2} are equivalent, we only need the invariant that shows equivalence on \emph{i} and \emph{result} for every iteration of the outer loop.
Additionally, to prove this invariant, we need to state that the inner loop of the left side has the same effect as the single assignement on the right: incrementing the \emph{result} by \emph{m}.
In this case, that reasoning comes to life through the assertion after the left inner loop and before the assigment to \emph{i}.
Notice the \emph{old(result)} inside that assertion? 
That represents the value that the result variable had in the previous loop iteration.


\FloatBarrier
\subsubsection{Conditionally aligned loops}
\label{subsubsec:cond_align_loops_example}

\begin{figure}[h]
  \centering

  \begin{subfigure}[t]{0.49\textwidth}
    \centering
    \noindent
    \begin{lstlisting}[escapeinside={(*}{*)}, style=while_lang,
                        emph={meth, while, do, result, done, old, invariant, assert, int, if, then, end},
                        emphstyle=\ttfamily\bfseries\color{myorange}]
meth ex1 (x: int, n: int) : int =
  y := x;
  z := 24; // 4!
  w := 0;

  while (y > 4) do
    if (w mod n = 0) then
      z := z * y;
      y := y - 1;
    end;

    w := w + 1;
  done;

  result := z;
    \end{lstlisting}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{0.49\textwidth}
    \centering
    \noindent
    \begin{lstlisting}[escapeinside={(*}{*)}, style=while_lang,
                        emph={meth, while, do, result, done, old, invariant, assert, int, if, then, end},
                        emphstyle=\ttfamily\bfseries\color{myorange}]
meth ex2 (x: int, n: int) : int =
  y := x;
  z := 16; // 2^4
  w := 0;

  while (y > 4) do
    if (w mod n = 0) then
      z := z * 2;
      y := y - 1;
    end;

    w := w + 1;
  done;

  result := z;
    \end{lstlisting}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{0.99\textwidth}
    \centering
    \noindent
    \begin{lstlisting}[escapeinside={(*}{*)}, style=while_lang, mathescape,
                        emph={meth, while, do, result, done, old, invariant, assert, int, if, then, end},
                        emphstyle=\ttfamily\bfseries\color{myorange}]
meth ex_bip (x: int, n: int | x: int, n: int) : (int | int) =
  $\lfloor$ y := x $\rfloor$;
  (z := 24 | z := 16);
  $\lfloor$ w := 0 $\rfloor$;

  while (y > 4) | (y > 4) . $\lhd$ w mod n $\neq$ 0 $\lhd$ | $\rhd$ w mod n $\neq$ 0 $\rhd$ do
    invariant { $\lhd$ z $\lhd$ > $\rhd$ z $\rhd$ $\land$ y $\doteq$ y $\land$ $\rhd$ y $\geq$ 4 $\rhd$ }

    if (w mod n = 0) | (w mod n = 0) then
      (z := z * y | z := z * 2);
      $\lfloor$ y := y - 1 $\rfloor$;
    end;

    $\lfloor$ w := w + 1 $\rfloor$;
  done;

  $\lfloor$ result := z $\rfloor$;
    \end{lstlisting}
  \end{subfigure}

  \caption{Programs that compute the factorial, the exponent of x $\geq$ 4 and a biprogram.}
  \label{fig:cond_align_loops_ex}
\end{figure}

The example presented in the previous subsubsection takes advantage of the fact that the two outer loops are executed the same number of times, which can be inferred from their conditions being the same (\emph{i < n}).
It allows a lockstep alignment of the loops' iterations, leading to simple relational invariants.
However, we can not exploit this lockstep reasoning on all cases, forcing us to use other patterns of loop alignment, such as those that consider conditions on data.

Considering the example in the \hyperref[fig:cond_align_loops_ex]{figure}, observe that \emph{ex1} calculates the factorial of \emph{x} and \emph{ex2} computes the result of \emph{$2^x$}, both for \emph{x $\geq$ 4}.
In this case, we do not want to prove the equivalence of \emph{ex1} and \emph{ex2}, but that the factorial majorizes the exponent for \emph{x $\geq$ 4}.
Therefore, we provide the following relational specification to reach that goal, keeping in mind that the post-condition, indicated by the \emph{ensures} keyword, should be interpreted as "the value of the variable \emph{result} of \emph{ex1} is strictly greater than its \emph{ex2}'s counterpart, after the execution ends".

\begin{figure}[h]
  \centering
  \noindent
  \begin{lstlisting}[escapeinside={(*}{*)}, style=while_lang, mathescape,
                      emph={meth, while, do, result, done, old, invariant, assert, int, requires, ensures, Both},
                      emphstyle=\ttfamily\bfseries\color{myorange}]
meth ex_bip_spec (x: int, n: int | x: int, n: int) : (int | int) =
  requires { x $\doteq$ x $\land$ $\rhd$ x $\geq$ 4 $\rhd$ $\land$ Both (n > 0) }
  ensures { $\lhd$ result $\lhd$ > $\rhd$ result $\rhd$ }
  \end{lstlisting}
  \caption{Relational spec for the example in \hyperref[fig:cond_align_loops_ex]{this} figure.}
  \label{fig:cond_align_loops_rel_spec}
\end{figure}

This relational spec means that, if at the start of the execution: both programs \emph{x's} are equal; \emph{ex2's x} is greater or equal to 4; and both \emph{n's} are strictly greater than 0, then the output of the left program will be strictly greater than the output of the right side.

\emph{ex1} and \emph{ex2} structure's are very similar and the example is simplified by setting the \emph{z} to 4! and $2^4$, respectively.
The \emph{w} variables' goal is to introduce \emph{stuttering} steps.
In this case, it restricts the loops from both sides to only execute the assignments to \emph{z} and \emph{y} when \emph{w} is divisible by \emph{n}.

Since the only restriction on \emph{n} is that they both sould be greater than 0, we can not be sure if the number of iterations will be the same for both sides, which excludes the possibility of providing an alignment based on pure lockstep.
Therefore, we should only align iterations in lockstep when \emph{w mod n = 0} on both sides; in other words, when the assignments to \emph{z} and \emph{y} will be performed.
For the other situations, when a side will not update those variables in the current iteration, the alignment of the iteration on the other side should be done with executing nothing, represented by the \emph{skip} command.
With these two types of alignments, we are able to establish the invariant $\lhd$ z $\lhd$ > $\rhd$ z $\rhd$.

This alignment is represented in terms of syntax by the \emph{ex\_bip} biprogram in \hyperref[fig:cond_align_loops_ex]{this} figure.
Conditional alignment is captured using additional annotations, the \emph{alignment guards}.
These annotations are general relation formulas that express conditions that cause the iterations to be either left-only, right-only or lockstep.
In our example, the alignment guards are \emph{$\lhd$ w mod n $\neq$ 0 $\lhd$ | $\rhd$ w mod n $\neq$ 0 $\rhd$}.
Looking at the left alignment guard, \emph{$\lhd$ w mod n $\neq$ 0 $\lhd$}, we understand that \emph{ex\_bip} executes left-only iterations when, on the left side, \emph{w} is \textbf{not} divisible by \emph{n}. 
A left-only iteration means that only the left side statements inside the loop are executed: \emph{if (w mod n = 0) then (z := z*y; y := y-1) end; w := w+1}.
The only assignment in this case is the increment of the \emph{w} variable, since the guard makes the if condition become false.
This reasoning is similar to the right side, representing the right-only iterations.
Finally, the lockstep iterations happen when both alignment guards are false; in this case, when \emph{w} is a multiple of \emph{n} on both sides.
This alignment allows us to use the relational invariants in \emph{ex\_bip} to prove that the post-condition holds after the execution of the biprogram.


\FloatBarrier
\subsection{Translating biprograms into product programs}
\label{subsec:whyrel_translation}

One of the main goals of WhyRel (also one of our main goals) is translating biprograms into product programs.
This tool achieves that through WhyML functions that act on a pair of states; WhyML functions that encode biprograms also act on a refperm, renaming references allocated in the two states being related.
However, before the translation phase, WhyRel checks how adequate the biprogram in question is.
At an intuition level, we can think that if the two unary programs are related in accord with a relational spec, then the biprogram is adequate if it satisfies that spec, which suggests that relatedness strongly impacts the correctness of the biprogram.

In practice, WhyRel confirms the adequacy of the biprogram in two phases, by checking if it can cover all pairs of executions of its two source programs.
The first phase is done by checking the syntax in order to ensure that the biprogram was really constructed from its underlying programs, through projection operations.
Consider the following notation, where \emph{CC} represents a biprogram, $\wideleftharpoonup{CC}$ its left projection (the left unary program) and $\widerightharpoonup{CC}$ its right projection (the right unary program).
As a simple example, the left projection of the following program is \textbf{x := 2; x := x + 1;} and the right projection is \textbf{x := x + 1;}.

\begin{lstlisting}[style=while_lang, mathescape,
                      emph={skip},
                      emphstyle=\ttfamily\bfseries\color{myorange}]
( x := 2 | skip);
$\lfloor$ x := x + 1 $\rfloor$;
\end{lstlisting}

Considering the unary original programs \emph{C} and \emph{C'}, the corresponding biprogram \emph{CC} and $\equiv$ the symbol for syntactic equality, WhyRel checks $\wideleftharpoonup{CC}$ $\equiv$ \emph{C} and $\widerightharpoonup{CC}$ $\equiv$ \emph{C'}.
The second phase consists in the introduction of annotations in the birpogram, such as assertions or loop invariants, by WhyRel, with the objective of ensuring adequacy.
In an hypothetical case where a biprogram aligns two loops in lockstep, this tool would add, as relational loop invariant, the equivalence of the two loop guards.

\begin{figure}[ht]
  \centering
  \begin{minipage}{0.99\linewidth}
  \begin{lstlisting}[escapeinside={(*}{*)},
      style=while_lang, 
      mathescape,
      columns=fixed,
      showspaces=false,       
      showstringspaces=false, 
      emph={var,in,let,if,then,else,while,do,invariant,assert},
      emphstyle=\ttfamily\bfseries\color{myorange}]
$\beta$$\llbracket C | C' \rrbracket$($\tau_l$,$\tau_r$)                      $\triangleq$ $\mu$$\llbracket C \rrbracket$($\tau_l$); $\mu$$\llbracket C' \rrbracket$($\tau_r$)

$\beta$$\llbracket \lfloor m(x|y) \rfloor \rrbracket$($\tau_l$,$\tau_r$)                   $\triangleq$ $\phi$(m)($\tau_l$.st,$\tau_r$.st,$\epsilon\llbracket x \rrbracket(\tau_l)$,$\epsilon\llbracket y \rrbracket(\tau_r)$)

$\beta$$\llbracket \lfloor C \rfloor \rrbracket$($\tau_l$,$\tau_r$)                       $\triangleq$ $\beta$$\llbracket C | C \rrbracket$($\tau_l$,$\tau_r$)

$\beta\llbracket$CC; DD$\rrbracket$($\tau_l$,$\tau_r$)                    $\triangleq$ $\beta\llbracket CC \rrbracket$($\tau_l$,$\tau_r$); $\beta\llbracket DD \rrbracket$($\tau_l$,$\tau_r$)

$\beta\llbracket$var x:T|x:T$'$ in CC$\rrbracket$($\tau_l$,$\tau_r$)        $\triangleq$ let $x_l$ = def(T) in 
                                                                        $\qquad$ $\qquad$ $\qquad$ let $x_r$ = def(T$'$) in 
                                                                        $\qquad$ $\qquad$ $\qquad$ $\beta\llbracket CC \rrbracket$([$\tau_l$ | x : $x_l$],[$\tau_r$ | x : $x_r$])

$\beta\llbracket$if E|E$'$ then CC else DD$\rrbracket$($\tau_l$,$\tau_r$)  $\triangleq$ assert{$\epsilon\llbracket$E$\rrbracket$($\tau_l$) = $\epsilon\llbracket$E$'$$\rrbracket$($\tau_r$)}; if $\epsilon\llbracket$E$\rrbracket$($\tau_l$) then $\beta\llbracket$CC$\rrbracket$($\tau_l$,$\tau_r$) else $\beta\llbracket$DD$\rrbracket$($\tau_l$,$\tau_r$)

$\beta\llbracket$while E|E$'$ do CC$\rrbracket$($\tau_l$,$\tau_r$)         $\triangleq$ while $\epsilon\llbracket$E$\rrbracket$($\tau_l$) do 
                                                                                  invariant {$\epsilon\llbracket$E$\rrbracket$($\tau_l$) = $\epsilon\llbracket$E$'$$\rrbracket$($\tau_r$)}
                                                                                  $\beta\llbracket CC \rrbracket$($\tau_l$,$\tau_r$)

$\beta\llbracket$while E|E$'$ . P|$P'$ do CC$\rrbracket$($\tau_l$,$\tau_r$)         $\triangleq$ while ($\epsilon\llbracket$E$\rrbracket$($\tau_l$) $\lor$ $\epsilon\llbracket$E$'$$\rrbracket$($\tau_r$)) do invariant {$A$}
                                                                                  if ($\epsilon\llbracket$E$\rrbracket$($\tau_l$) $\land$ $\digamma\llbracket P \rrbracket$($\tau_l$,$\tau_r$)) then $\mu$$\llbracket \wideleftharpoonup{CC} \rrbracket$($\tau_l$)
                                                                                  else if ($\epsilon\llbracket$E$'$$\rrbracket$($\tau_r$) $\land$ $\digamma\llbracket P$'$ \rrbracket$($\tau_l$,$\tau_r$)) then  $\mu$$\llbracket \widerightharpoonup{CC} \rrbracket$($\tau_r$) else $\beta\llbracket$CC$\rrbracket$($\tau_l$,$\tau_r$)
                                                                            where $A$ $\equiv$ () $\lor$ () $\lor$ () $\lor$ () COMPLETE HERE!
  \end{lstlisting}
  \end{minipage}
  \caption{Rules of translation of biprograms.}
  \label{fig:translation-biprograms-rules}
\end{figure}

\begin{figure}[ht]
  \centering
  \begin{minipage}{0.99\linewidth}
    \setlength{\tabcolsep}{6pt}
    \begin{tabularx}{\linewidth}{@{}L R@{}}

      $\beta\llbracket C \mid C' \rrbracket(\tau_l,\tau_r)$ &
      \parbox[t]{\hsize}{$\triangleq\ \mu\llbracket C\rrbracket(\tau_l);\ \mu\llbracket C'\rrbracket(\tau_r)$} \\[6pt]

      $\beta\llbracket \lfloor m(x\mid y) \rfloor \rrbracket(\tau_l,\tau_r)$ &
      \parbox[t]{\hsize}{$\triangleq\ \phi(m)\big(\tau_l.\mathrm{st},\tau_r.\mathrm{st},
      \epsilon\llbracket x\rrbracket(\tau_l),\epsilon\llbracket y\rrbracket(\tau_r)\big)$} \\[6pt]

      $\beta\llbracket \lfloor C \rfloor \rrbracket(\tau_l,\tau_r)$ &
      \parbox[t]{\hsize}{$\triangleq\ \beta\llbracket C \mid C \rrbracket(\tau_l,\tau_r)$} \\[6pt]

      $\beta\llbracket CC;\,DD\rrbracket(\tau_l,\tau_r)$ &
      \parbox[t]{\hsize}{$\triangleq\ \beta\llbracket CC \rrbracket(\tau_l,\tau_r);\ \beta\llbracket DD \rrbracket(\tau_l,\tau_r)$} \\[6pt]

      $\beta\llbracket \kw{var }x:T \mid x:T' \kw{ in } CC\rrbracket(\tau_l,\tau_r)$ &
      \parbox[t]{\hsize}{%
        $\triangleq\ \kw{let}\ x_l=\mathrm{def}(T)\ \kw{in}$\\[2pt]
        \hspace{2.2em}$\kw{let}\ x_r=\mathrm{def}(T')\ \kw{in}$\\[2pt]
        \hspace{2.2em}$\beta\llbracket CC \rrbracket\big([\tau_l\mid x:x_l],[\tau_r\mid x:x_r]\big)$
      } \\[8pt]

      $\beta\llbracket \kw{if } E\mid E' \ \kw{then}\ CC\ \kw{else}\ DD\rrbracket(\tau_l,\tau_r)$ &
      \parbox[t]{\hsize}{%
        $\triangleq\ \kw{assert}\{\ \epsilon\llbracket E\rrbracket(\tau_l)=\epsilon\llbracket E'\rrbracket(\tau_r)\ \};$\\[2pt]
        \hspace{2.2em}$\kw{if}\ \epsilon\llbracket E\rrbracket(\tau_l)\ \kw{then}\ \beta\llbracket CC\rrbracket(\tau_l,\tau_r)\ \kw{else}\ \beta\llbracket DD\rrbracket(\tau_l,\tau_r)$
      } \\[8pt]

      $\beta\llbracket \kw{while } E\mid E' \ \kw{do}\ CC\rrbracket(\tau_l,\tau_r)$ &
      \parbox[t]{\hsize}{%
        $\triangleq\ \kw{while}\ \epsilon\llbracket E\rrbracket(\tau_l)\ \kw{do}$\\[2pt]
        \hspace{2.2em}$\kw{invariant}\ \{\ \epsilon\llbracket E\rrbracket(\tau_l)=\epsilon\llbracket E'\rrbracket(\tau_r)\ \}$\\[2pt]
        \hspace{2.2em}$\beta\llbracket CC\rrbracket(\tau_l,\tau_r)$
      } \\[8pt]

      $\beta\llbracket \kw{while } E\mid E' .\ P\mid P' \ \kw{do}\ CC\rrbracket(\tau_l,\tau_r)$ &
      \parbox[t]{\hsize}{%
        $\triangleq\ \kw{while}\ (\epsilon\llbracket E\rrbracket(\tau_l)\ \lor\ \epsilon\llbracket E'\rrbracket(\tau_r))\ \kw{do}\ \kw{invariant}\ \{A\}$\\[2pt]
        \hspace{2.2em}$\kw{if}\ (\epsilon\llbracket E\rrbracket(\tau_l)\ \land\ $F$\llbracket P\rrbracket(\tau_l,\tau_r))\ \kw{then}\ \mu\llbracket \wideleftharpoonup{CC}\rrbracket(\tau_l)$\\[2pt]
        \hspace{2.2em}$\kw{else if}\ (\epsilon\llbracket E'\rrbracket(\tau_r)\ \land\ $F$\llbracket P'\rrbracket(\tau_l,\tau_r))\ \kw{then}\ \mu\llbracket \widerightharpoonup{CC}\rrbracket(\tau_r)$\\[2pt]
        \hspace{2.2em}$\kw{else}\ \beta\llbracket CC\rrbracket(\tau_l,\tau_r)$\\[4pt]
        \hspace{0.0em}\text{where } $A \equiv () \lor () \lor () \lor ()\ \text{COMPLETE HERE!}$
      } \\

    \end{tabularx}
  \end{minipage}
  \caption{Rules of translation of biprograms.}
  \label{fig:translation-biprograms-rules}
\end{figure}

--- CONTINUE TEXT ---



\subsubsection{Translation example}
\label{subsubsec:whyrel_translation_example}
completar exemplo do mult com product program EM WHYML!!!

